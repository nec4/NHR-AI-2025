{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05bb6a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "from glob import glob\n",
    "from typing import Dict, List\n",
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import pytorch_hpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeb3cd1-edcf-4700-bb15-ada0cdd221ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "me = subprocess.run([\"whoami\"], capture_output=True).stdout.decode('utf').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b143efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_scalar_data(fname: str, report_info=True) -> Dict[str,List]:\n",
    "    \"\"\"Returns a dictionary of str:List pairs that correspond to \n",
    "    scalar tags and their list of ScalarEvents\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fname:\n",
    "        Full path to the desired tensorboard events.out file\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    data_dict:\n",
    "        Dictionary of tag:List[Scalar.Event]\n",
    "    \"\"\"\n",
    "    events = EventAccumulator(fname)\n",
    "    events.Reload()\n",
    "    scalar_tags = events.Tags()['scalars']\n",
    "    data_dict = {}\n",
    "    for tag in scalar_tags:\n",
    "        data_dict[tag] = events.Scalars(tag)\n",
    "\n",
    "    if report_info:\n",
    "        wts = [i.wall_time for i in data_dict[\"epoch\"]] \n",
    "        avg = np.average(np.diff(wts))\n",
    "        std = np.std(np.diff(wts))\n",
    "        total = wts[-1] - wts[1]\n",
    "        print(f\"Summary for {fname}:\")\n",
    "        print(\"====================\")\n",
    "        print(f\"Total training time: {total:.4f} (s)\")\n",
    "        print(f\"Average training time: {avg:.4f} +/- {std:.2f} (s)\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    return data_dict\n",
    "\n",
    "def get_last_logfile(directory: str) -> str:\n",
    "    \"\"\"Grabs the last tensorboard eventfile in the specified directory\"\"\"\n",
    "\n",
    "    files = list(glob.glob(directory + \"/events*\"))\n",
    "    if len(files) == 0:\n",
    "        print(f\"No event files found in {directory}\")\n",
    "        return None\n",
    "        \n",
    "    files = [f for f in files if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "    files_sorted = sorted(files, key=lambda f: os.path.getmtime(os.path.join(directory, f)))\n",
    "    return files_sorted[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e508ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "work = f\"/home/woody/k_t70h/{me}\"\n",
    "\n",
    "cpu_logfile = get_last_logfile(f\"{work}/NHR-AI-2025/pytorch_tests/fashion_mnist_cpu/tensorboard\")\n",
    "gpu_logfile = get_last_logfile(f\"{work}/NHR-AI-2025/pytorch_tests/fashion_mnist_gpu/tensorboard\")\n",
    "cpu_data = extract_scalar_data(cpu_logfile)\n",
    "gpu_data = extract_scalar_data(gpu_logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9222940c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datas = [cpu_data, gpu_data]\n",
    "colors = [\"blue\",\"red\"]\n",
    "labels = ['CPU','GPU']\n",
    "\n",
    "for data_dict, color, label in zip(datas, colors, labels):\n",
    "    vals = [ev.value for ev in data_dict['validation_loss']]\n",
    "    trains  = [ev.value for ev in data_dict['training_loss']]\n",
    "    plt.plot(trains, label=f\"{label} Train\", color=color, linestyle='--')\n",
    "    plt.plot(vals, label=f\"{label} Val\", color=color)\n",
    "\n",
    "plt.ylabel(r\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a2f4b9-b0de-4e9b-aedd-78329e56f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pytorch_hpc.nn.models.ConvolutionClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15da524-b5ad-46e0-b4f9-59d51c3781c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fc4eb2-d33c-4c1b-a5c6-e71df66cd639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
